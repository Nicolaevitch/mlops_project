# mlops_project

## Objectifs du projet

1. Extraire et pr√©traiter les donn√©es : t√©l√©charger les images depuis les URLs, les nettoyer et les pr√©parer pour l'entra√Ænement.

2. Construire un mod√®le de classification : d√©velopper un mod√®le de deep learning permettant de classer les images en deux cat√©gories (dandelion vs grass). Utilisez la techno la plus adapt√©e √† vos besoins : FastAI, PyTorch, Tensorflow, etc.

3. Stocker le mod√®le sur AWS S3 (Minio) : une fois entra√Æn√©, le mod√®le devra √™tre sauvegard√© dans un bucket S3.

4. Cr√©er un pipeline de r√©entra√Ænement avec Apache Airflow : mettre en place un
pipeline qui r√©cup√®re les nouvelles donn√©es, met √† jour le mod√®le et le red√©ploie.

5. Suivre les mod√®les et les exp√©riences avec MLFlow : utiliser MLFlow pour enregistrer les performances et suivre les versions du mod√®le.

6. D√©velopper une API : construire une API permettant d'envoyer une image et de
recevoir une pr√©diction. Utilisez la techno la plus adapt√©e √† vos besoins : FastAPI, Flask, KServe, Torch Serve, etc.

7. Cr√©er une WebApp pour interagir avec le mod√®le : d√©velopper une interface
utilisateur simple pour visualiser les r√©sultats des pr√©dictions. Utilisez la techno la plus adapt√©e √† vos besoins : Gradio, Streamlit, Voila, etc.

8. Dockeriser votre API et d√©ployer l√† sur un cluster Kubernetes en local (Docker Desktop ou MiniKube). Utilisez la CI/CD de GitHub Actions pour cel√†.

9. Versionner et documenter le projet sur GitHub : tout le projet devra √™tre h√©berg√© sur GitHub, avec une structure de fichiers propre et une documentation claire.

10. Ajouter du monitoring pour visualiser l‚Äôensemble des m√©triques que vous souhaitez monitorer (ex: airflow, API, performances du mod√®le, etc.). Utilisez la techno la plus adapt√©e √† vos besoins : Elasticsearch + Kibana, Prometheus + Grafana, etc.

11. Vous pouvez ajouter des tests de mont√©e en charge (ex: avec Locust)

12. On souhaite maintenant faire de l'Entra√Ænement Continue (CT). Ajouter un ou plusieurs DAG Airflow avec des triggers que vous d√©finirez (nouvelle donn√©es, entrainement hebdomadaire, performances du mod√®le en baisse, etc.) pour r√©entra√Æner et d√©ployer automatiquement un nouveau mod√®le.

## üîß Lancement du projet

1. Lancez l'ensemble des services avec Docker Compose :
   <pre> docker-compose -f docker-compose.yaml up -d   </pre>
   Services inclus :

   - Airflow : Orchestration des workflows

   - MinIO : Stockage d'objets pour les donn√©es et du mod√®le entra√Æn√© 

   - MLflow : Suivi des exp√©riences ML üìä

   - Redis : Cache et syst√®me de message

   - API : Service d'inf√©rence du mod√®le (FastAPI)

   - Streamlit : Interface utilisateur üñ•Ô∏è
   ![docker build 1](https://github.com/user-attachments/assets/3228efa9-5cd5-4811-85b2-fc4d12a19c49)

   NB : Nous avons fait le choix de ne pas utiliser de service MySQL pour stocker les donn√©es tabulaires mais plut√¥t d'automatiser avec Airflow la g√©n√©ration et mise √† jour d'un fichier csv dans le dossier data du projet Git. Compte tenu de la taille du dataset (400 lignes), cette m√©thode nous paraissait plus directe et efficace.

2. Construction du bucket "images-bucket" sur minio
   - Acc√©dez √† l'interface MinIO (http://localhost:9001)

   - Cr√©ez un bucket nomm√© images-bucket

   - Configurez les permissions d'acc√®s
   #ajouter le screen du dossier ou ce trouve le mod√®le


   ![Minio1 1](https://github.com/user-attachments/assets/4948ad64-6a9a-41de-8113-78a06ff802f9)

   ![Minio2 1](https://github.com/user-attachments/assets/18f060fa-2265-49a5-857f-e841245fd36f)
   
3. Ex√©cution du Workflow Airflow
   - Acc√©dez √† l'interface Airflow (http://localhost:8080)

   - Activez le DAG principal

   - Ps: Il faut configurer une connexion Minio S3 dans Airflow via l'UI d'Airflow, onglet Connections, pour permettre le t√©l√©chargement des images vers le bucket S3.

   ![dag 1](https://github.com/user-attachments/assets/87ff28a9-f7bb-42dd-a12e-d399128b33c2)

**üìö Guide d'Utilisation**
1. Acc√©dez √† MLflow (http://localhost:5001) pour :
   - Comparer les performances des mod√®les

   - Visualiser les m√©triques

   - G√©rer les versions des mod√®les
     #ajouter le screen de differentes etapes du mod√®les (plusieurs train)
   ![ml_flow 1](https://github.com/user-attachments/assets/90164a7f-cd0c-4a76-8b5b-0cbd8a6fc197)

2. l'interface utilisateur qui permet d'utiliser notre mod√®le üñ•Ô∏è
   - Acc√©dez √† l'application (http://localhost:8501)

   - Chargez vos donn√©es

   - Visualisez les pr√©dictions
     
![streamlit2 1](https://github.com/user-attachments/assets/dfa1ecbb-3b5c-4da1-8e68-5ac67f6e3ee0)
![streamlit1 1](https://github.com/user-attachments/assets/09af827b-fd2b-4385-81f2-6fe416c046ef)

## üåø Gestion des Branches Git

### Strat√©gie de Branches
Nous utilisons un workflow Git avec deux branches principales (main et dev) et des sous branches :

main ‚Üí Branche stable (production)

‚îî‚îÄ‚îÄ dev ‚Üí Branche d'int√©gration (d√©veloppement)

‚îú‚îÄ‚îÄ sous branche 1

‚îú‚îÄ‚îÄ sous branche 2

‚îú‚îÄ‚îÄ sous branche 3

‚îî‚îÄ‚îÄ sous branche 4

## üîÑ Int√©gration Continue avec GitHub Actions
### Workflow d'Ex√©cution
Notre pipeline CI s'ex√©cute automatiquement √† chaque push via GitHub Actions :
![image](https://github.com/user-attachments/assets/c671cdd5-4adc-462e-ae5c-4dc399aea8af)

## Choix du mod√®le
L'objectif du projet √©tait d'utiliser du deep learning, bien qu'une simple r√©gression logistique aurait √©galement eu de tr√®s bonnes performances pour cette t√¢che.
Nous avons choisi de le d√©velopper avec Pytorch un petit r√©seaux de neurone √† 34 couches (resnet34).


## Difficult√©s
1/ Nous avons commenc√© par construire les services Docker sur mac os mais avons eu de nombreux probl√®mes de comptabilit√© qui nous ont oblig√© de revoir toute une partie du code pour les rendre compatible sur windows / linux. Cependant une fois fonctionnel sur windows/linux, ils ne l'√©taient plus sur mac os. Nous n'avons pas r√©ussi √† aboutir √† une version fonctionnelle sur les deux os. De plus la branche dev a trop d√©vi√© de la branche main donc nous avons r√©alis√© un git reset --hard dev, perdant ainsi les insights de la branche main. Ci-dessous une sauvegarde des commits. 
<img width="1261" alt="image" src="https://github.com/user-attachments/assets/8a3ad146-0de2-46aa-ac44-744941662fe4" />


2/ Le d√©ploiement Kubernetes (en local) ne fonctionne que pour 3 services : minio, mlflow et postgres.




   
